###--------Problem Set 3 Big Data and Machine Learning------------###
###--------Daniela Jaime, Maria Paula Nieto, Juan Diego Lopez---------

##Paquetes 
rm(list = ls())

#install.packages("devtools")
require("pacman")
p_load("ggpubr")
p_load(faraway)
p_load(tidyverse)
p_load(skimr)
#devtools::install_github("boxuancui/DataExplorer")
p_load(DataExplorer)
p_load(scales)
p_load(corrr)
p_load(MASS)
p_load(class)
p_load(dplyr) #for data wrangling
p_load(gamlr)
p_load(dplyr)
p_load(glmnet)
p_load(pls)
#devtools::install_github("thomasp85/patchwork")
p_load(rvest)
p_load(rio) 
p_load(tidyverse)
p_load(e1071) 
p_load(EnvStats) 
p_load(tidymodels) 
p_load(ggplot2) 
p_load(scales) 
p_load(ggpubr) 
p_load(knitr) 
p_load(kableExtra)
p_load(broom)
p_load(caret)
p_load(rio,
       sf, # Leer/escribir/manipular datos espaciales
       leaflet, # Visualizaciones dinámicas
       tmaptools, # geocode_OSM()
       osmdata) # Get OSM's data
p_load(corrplot)

#Recuerden hacer el set de su directorio

#Cargar Datos

train <- readRDS("dataPS3/train.Rds")
test <- readRDS("dataPS3/test.Rds")

str(train)
summary(train)
summary(test)

##Se analizan los Nas
cantidad_na <- sapply(train, function(x) sum(is.na(x))) #Una función que me suma el número de NAs por variable
cantidad_na <- data.frame(cantidad_na) #Lo convierto en Data Frame
porcentaje_na <- cantidad_na/nrow(train) #Le saco el porcentaje de Missing values a cada variable

# Porcentaje de observaciones faltantes. 
porcentaje <- mean(porcentaje_na[,1]) #El 11.11% de las variables tiene NAs
print(paste0("En promedio el ", round(porcentaje*100, 2), "% de las entradas están vacías"))

##Ordenamos de mayor a menor
porcentaje_na <- arrange(porcentaje_na, desc(cantidad_na))
# Convertimos el nombre de la fila en columna
porcentaje_na <- rownames_to_column(porcentaje_na, "variable")

orden <- porcentaje_na$variable[length(porcentaje_na$variable):1] #Se vuelven caracteres
porcentaje_na$variable <- factor(porcentaje_na$variable,
                                 levels = orden) #Se utilizan como factores para poder graficar

ggplot(porcentaje_na[1:nrow(porcentaje_na),], 
       aes(y = variable, x = cantidad_na)) +
  geom_bar(stat = "identity", fill = "darkslategray3") +
  geom_text(aes(label = paste0(round(100*cantidad_na, 1), "%")),
            colour = "white", position = "dodge", hjust = 1.3,
            size = 2, fontface = "bold") +
  theme_classic() +
  labs(x = "Porcentaje de NAs", y = "Variables") +
  scale_x_continuous(labels = scales::percent, limits = c(0, 1))

#Hay cuatro variables con muchos NAs: rooms, bathrooms, surface_total, surface_covered

#--------Combinar las bases-----------------
#Vamos a unir las bases test y train para hacer más fácil la transformación
test$test <- 1 #Binaria que me dice que este set es de test
train$test <- 0 #0 porque no son parte del test

test$price <- NA #Se crea la variable precio en Test como NAs para incluirla y poder combinar las bases

df <- rbind(train, test)

#Ahora es necesario volver el df un shape file
df_sf = st_as_sf(x=df,coords=c("lon","lat"),crs=4326)
class(df_sf)

table(df_sf$l3)

#Dvidir el set en Bogotá y Medellin 
df_sf_bog <- df_sf %>% filter(l3 == "Bogotá D.C")
df_sf_med <-  df_sf %>% filter(l3 == "Medellín")

#----------Visualización de los datos en el mapa-------------------

#Mirar los Mapas de cada ciudad
leaflet() %>% addTiles() %>% addCircleMarkers(data=df_sf_bog, color = "red", weight = 2)
leaflet() %>% addTiles() %>% addCircleMarkers(data=df_sf_med, color = "red", weight = 2)

#Este problem set se centra en Chapinero y El Poblado, por lo que se mirarán estas dos localidades

#Chapinero
chapinero <- getbb(place_name = "UPZ Chapinero, Bogota", 
                   featuretype = "boundary:administrative", 
                   format_out = "sf_polygon") %>% .$multipolygon

df_sf_chapinero <- st_crop (df_sf, chapinero)

leaflet() %>% addTiles() %>% addPolygons(data=chapinero) %>%
                            addCircleMarkers(data=df_sf_chapinero, color = "red", weight = 2)

#Poblado
poblado <- getbb(place_name = "Comuna 14 - El Poblado", 
                 featuretype = "boundary:administrative", 
                 format_out = "sf_polygon")

leaflet() %>% addTiles() %>% addPolygons(data=poblado)

df_sf_poblado <- st_crop (df_sf, poblado)

leaflet() %>% addTiles() %>% addPolygons(data=poblado) %>%
  addCircleMarkers(data=df_sf_poblado, color = "red", weight = 2)

#---------Limpieza y Analisis de Datos--------------------

#Análisis 
str(df_sf)
skim(df_sf)

#Con SKim nos damos cuenta que hay información que no es necesaria para los modelos
#Se eliminarán
df_sf <- df_sf %>% dplyr::select(-ad_type, -l1, -l2, -currency,
                                 -operation_type)

#Volver algunas variables como factores
df_sf <- df_sf %>%
  mutate_at(.vars = c("l3", "property_type"),
    .funs = factor)

#Correlaciones
MCor <- df %>% dplyr::select(rooms, bedrooms, bathrooms, surface_total,
                         surface_covered, price)

M <- cor(MCor, use = "pairwise.complete.obs")
corrplot(M, method = "ellipse", type = "full")

#Visualización de variables
ggplot(df_sf, aes(x = price)) + geom_histogram()
ggplot(df_sf, aes(x = price)) + geom_boxplot()

ggplot(df_sf, aes(x = rooms)) + geom_histogram()
ggplot(df_sf, aes(x = rooms)) + geom_boxplot()

ggplot(df_sf, aes(x = bedrooms)) + geom_histogram()
ggplot(df_sf, aes(x = bedrooms)) + geom_boxplot()

ggplot(df_sf, aes(x = surface_covered)) + geom_histogram()
ggplot(df_sf, aes(x = surface_covered)) + geom_boxplot()

#Variables categoricas y su relacion con el precio
ggplot(df_sf, aes(x = price)) + geom_boxplot() + facet_wrap(~ l3)

ggplot(df_sf, aes(x = price)) + geom_boxplot() + facet_wrap(~ property_type)

#Algunas combinaciones
ggplot(df_sf, aes(x = bathrooms, y= price, color = l3)) + geom_point()
ggplot(df_sf, aes(x = bedrooms, y= price, color = l3)) + geom_point()
ggplot(df_sf, aes(x = surface_covered, y= price, color = l3)) + geom_point()

#Sacar los metros cuadrados en descripción
#Sacar la distancia a los business centers
#Tratar los missing con los vecinos más cercanos, utilizar el promedio de la misma cuadra o utilizar la mediana
#Utilizar bases externas para crear otras variables 
#(i.e distancia a los bares o comercio, distancia a los parques, paraderos de bus, criminalidad, distancia a colegios)

#------Data Cleaning---------------

#------Dividir la muestra train dos submuestras-------------

#------------Modelos Continuos-----------------

#----------Modelo Lasso------------
#----------Modelo XGboost-----------

####OJO SI EL PRECIO ESTÁ MENOR EN 40 MILLONES O 10000 USD TENDREMOS PENALIZACIÓN #####


